python3 extract_video_frames.py --videopath /media/data_1/snva/Data/fhwa/shrp2_nds/batch_11 --imagepath /media/data_1/snva/Data/fhwa/shrp2_nds --crop --cropx 2 --cropy 0 --cropwidth 474 --cropheight 320 --fps=14.985015

(monitor training and evaluation) tensorboard --logdir=/media/data_1/snva/Checkpoints/fhwa/shrp2_nds

(evaluate while training) python3 eval_image_classifier.py --mode=periodic --eval_dir=/media/data_1/snva/Checkpoints/fhwa/shrp2_nds/active_learning_round_1/mobilenet_v1/transfer_init_rmsprop/dev --checkpoint_path=/media/data_1/snva_1/Checkpoints/fhwa/shrp2_nds/active_learning_round_1/mobilenet_v1/transfer_init_rmsprop --dataset_dir=/media/data_0/snva_0/Data_Sets/fhwa/shrp2_nds --dataset_name=active_learning_round_1 --dataset_split_name=dev --model_name=mobilenet_v1 --batch_size=32 --num_preprocessing_threads=4 --num_readers=4 --cpu_only

(kick off training) python3 train_image_classifier.py --train_dir=/media/data_1/snva_1/Checkpoints/fhwa/shrp2_nds/active_learning_round_1_data_set/mobilenet_v1/transfer_init_rmsprop --checkpoint_path=/media/data_1/snva_1/Checkpoints/fhwa/shrp2_nds/active_learing_round_1_data_set/mobilenet_v1/transfer_init_rmsprop --dataset_dir=/media/data_0/snva_0/Data_Sets/fhwa/shrp2_nds --dataset_name=active_learning_round_1_data_set --checkpoint_exclude_scopes=InceptionV3/Logits,InceptionV3/AuxLogits --batch_size=32 --optimizer=adam --log_every_n_steps=2199 --save_interval_secs=300 --save_summaries_secs=300 --max_checkpoints_to_keep=1000 --dropout_keep_prob=0.2 --num_preprocessing_threads=16 --num_readers=16 --num_clones=2

(resume training) python3 train_image_classifier.py --train_dir=/media/data_1/snva/Checkpoints/fhwa/shrp2_nds/active_learning_seed_data_set/inception_v3/transfer_init_from_fhwa_iv_seed_set_c --dataset_dir=/media/data_1/snva/Data_Sets/fhwa/shrp2_nds --dataset_name=active_learning_seed_data_set --batch_size=32 --optimizer=adam --log_every_n_steps=2199 --save_interval_secs=300 --save_summaries_secs=300 --max_checkpoints_to_keep=1000 --dropout_keep_prob=0.2 --num_preprocessing_threads=16 --num_readers=16 --num_clones=2

(convert training checkpoint file to protobuf file) python3 export_inception_v3_alt.py --checkpoint_path=/media/data_1/snva/Checkpoints/fhwa/shrp2_nds/active_learning_seed_data_set/inception_v3/transfer_init_from_fhwa_iv_seed_set_c/model.ckpt-27436 --protobuf_file=/media/data_1/snva/Models/saved/fhwa/shrp2_nds/active_learning_seed_data_set/transfer_init_from_fhwa_iv_seed_set_c_27436.pb --num_classes=4

(automatically label videos and group labels by confidence in prediction) python3 predict_class_labels.py --raw_data_dir=/media/data_1/snva/Raw_Data/fhwa/shrp2_nds --label_predictions_dir=/media/data_1/snva/Label_Predictions/fhwa/shrp2_nds/active_learning_seed_data_set --data_set_dir=/media/data_1/snva/Data_Sets/fhwa/shrp2_nds/active_learning_seed_data_set --model_path=/media/data_1/snva/Models/saved/fhwa/shrp2_nds/active_learning_seed_data_set/inception_v3/transfer_init_from_fhwa_iv_seed_set_c_27436.pb --batch_size=512 --gpu_device_num=0

(read names of video files to label from a txt file) python3 predict_class_labels.py --raw_data_dir=/media/data_1/snva/Raw_Data/fhwa/shrp2_nds --label_predictions_dir=/media/data_1/snva/Label_Predictions/fhwa/shrp2_nds/active_learning_seed_data_set --data_set_dir=/media/data_1/snva/Data_Sets/fhwa/shrp2_nds/active_learning_seed_data_set --model_path=/media/data_1/snva/Models/saved/fhwa/shrp2_nds/active_learning_seed_data_set/inception_v3/transfer_init_from_fhwa_iv_seed_set_c_27436.pb --batch_size=512 --gpu_device_num=1 --video_names_path=/home/franklin/Desktop/process_1_names.txt

python3 model_development/predict_class_labels.py --raw_data_dir=/media/franklin/d5083f8e-224a-4a05-a37f-650abf34887c/snva_0/Raw_Data/fhwa/shrp2_nds/Video_Frames --label_predictions_dir=/media/franklin/d5083f8e-224a-4a05-a37f-650abf34887c/snva_0/Model_Predictions/fhwa/shrp2_nds/active_learning_round_1/mobilenet_v2_1.4/coarse_tune_init_frozen_L1_L4_rmsprop_38796 --data_set_dir=/media/franklin/d5083f8e-224a-4a05-a37f-650abf34887c/snva_0/Data_Sets/fhwa/shrp2_nds/active_learning_round_1_data_set --report_dir_path=/media/franklin/d5083f8e-224a-4a05-a37f-650abf34887c/snva_0/Reports/fhwa/shrp2_nds/active_learning_round_1/mobilenet_v2_1.4/coarse_tune_init_frozen_L1_L4_rmsprop_38796/report_test

python3 model_development/predict_class_labels.py --raw_data_dir=/media/franklin/d5083f8e-224a-4a05-a37f-650abf34887c/snva_0/Raw_Data/fhwa/shrp2_nds/Video_Frames --label_predictions_dir=/media/franklin/d5083f8e-224a-4a05-a37f-650abf34887c/snva_0/Model_Predictions/fhwa/shrp2_nds/active_learning_round_1/mobilenet_v2_1.4/coarse_tune_init_frozen_L1_L4_rmsprop_38796 --data_set_dir=/media/franklin/d5083f8e-224a-4a05-a37f-650abf34887c/snva_0/Data_Sets/fhwa/shrp2_nds/active_learning_round_1_data_set --report_dir_path=/media/franklin/d5083f8e-224a-4a05-a37f-650abf34887c/snva_0/Reports/fhwa/shrp2_nds/active_learning_round_1/mobilenet_v2_1.4/coarse_tune_init_frozen_L1_L4_rmsprop_38796/report_test

python3 model_development/predict_class_labels.py --data_set_dir=/media/data_0/snva_0/Data_Sets/fhwa/shrp2_nds/active_learning_round_1_data_set --report_dir_path=/media/data_0/snva_0/Reports/fhwa/shrp2_nds/active_learning_round_1/mobilenet_v2_1.4/coarse_tune_init_frozen_L1_L4_rmsprop_38796/report_test --raw_data_dir=/media/data_0/snva_0/Raw_Data/fhwa/shrp2_nds/Video_Frames --label_predictions_dir=/media/data_0/snva_0/Model_Predictions/fhwa/shrp2_nds/active_learning_round_1/mobilenet_v2_1.4/coarse_tune_init_frozen_L1_L4_rmsprop_38796/previously_used

python3 model_development/eval_image_classifier.py --mode=periodic --eval_dir=/media/data_1/snva/Checkpoints/fhwa/shrp2_nds/active_learning_round_1/mobilenet_v2_050/transfer_init_rmsprop/dev --checkpoint_path=/media/data_1/snva_1/Checkpoints/fhwa/shrp2_nds/active_learning_round_1/mobilenet_v2_050/transfer_init_rmsprop --dataset_dir=/media/data_0/snva_0/Data_Sets/fhwa/shrp2_nds --dataset_name=active_learning_round_1_data_set --dataset_split_name=dev --model_name=mobilenet_v2_050 --batch_size=16 --num_preprocessing_threads=2 --num_readers=2 --gpu_device_num=0 --gpu_memory_fraction=0.2